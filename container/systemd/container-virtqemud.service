[Unit]
Description=Virtualization qemu daemon
Conflicts=libvirtd.service virtqemud.service
Requires=virtlogd.socket
Requires=virtlockd.socket
Requires=virtqemud.socket
Requires=virtqemud-ro.socket
Requires=virtqemud-admin.socket
Wants=systemd-machined.service
Before=libvirt-guests.service
After=kvm-container-meta.service
BindsTo=kvm-container-meta.service
Documentation=man:virtqemud(8)
Documentation=https://libvirt.org

[Service]
Type=forking
Environment=VIRTQEMUD_ARGS=""
Environment=CONTAINER_NAME="kvm-container"
EnvironmentFile=-/etc/sysconfig/container-virtqemud
EnvironmentFile=-/etc/kvm-container.conf
ExecStart=/usr/bin/podman exec --detach --privileged ${CONTAINER_NAME} /usr/sbin/virtqemud $VIRTQEMUD_ARGS
Restart=on-failure
RestartSec=2
# At least 1 FD per guest, often 2 (eg qemu monitor + qemu agent).
# eg if we want to support 4096 guests, we'll typically need 8192 FDs
# If changing this, also consider container-virtlogd.service & container-virtlockd.service
# limits which are also related to number of guests
LimitNOFILE=8192
# The cgroups pids controller can limit the number of tasks started by
# the daemon, which can limit the number of domains for some hypervisors.
# A conservative default of 8 tasks per guest results in a TasksMax of
# 32k to support 4096 guests.
TasksMax=32768
# With cgroups v2 there is no devices controller anymore, we have to use
# eBPF to control access to devices.  In order to do that we create a eBPF
# hash MAP which locks memory.  The default map size for 64 devices together
# with program takes 12k per guest.  After rounding up we will get 64M to
# support 4096 guests.
LimitMEMLOCK=64M

[Install]
WantedBy=multi-user.target
Also=virtlogd.socket
Also=virtlockd.socket
Also=virtqemud.socket
Also=virtqemud-ro.socket
Also=virtqemud-admin.socket
